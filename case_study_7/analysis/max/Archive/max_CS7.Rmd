---
title: "Max_CS7"
author: "Nikhil, Moro, Bhuvana"
date: "11/21/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(tidyverse)
library(qs)
library(cowplot)
library(ggrepel)
library(scales)
library(future)
library(pryr)
library(tictoc)
library(pROC)
```

# Loading Data

```{r}
#folder = 'C:/max/OneDriveSMU/OneDrive - Southern Methodist University/2020-08 QTW/CS7'
folder='x:/MMORO/Max.Master MSDS'
if(F){
  dataRaw = read.csv(file.path(folder,'final_project.csv'))
  saveRDS(data_raw,file.path(folder,'final_project.rds'))
}  else{
  dataRaw = readRDS(file.path(folder,'final_project.rds'))
}

dataRaw = dataRaw %>%
  mutate(y = ifelse(y==1,'y','n')
         ,x37 = as.numeric(gsub('[$,]','',x37))
         ,x32 = as.numeric(gsub('[%,]','',x32))/100
  )

```


# EDA

## numeric Columns

```{r fig.height=20, fig.width=10}
numCols = colnames(dataRaw)[which(lapply(dataRaw,class)=='numeric')]
```

### Checking Missing Values

```{r}
NAs = sapply(numCols,function(col){sum(is.na(dataRaw[[col]]))})
print(NAs)
NAsRows = unique(unlist(lapply(numCols,function(col){which(is.na(dataRaw[[col]]))})))
print(length(NAsRows))

```
### Variables Distribution

```{r fig.height=20, fig.width=10}


p = lapply(numCols
           ,function(col){
             dt=dataRaw[-NAsRows,]
             annotation = data.frame(x = min(dt[[col]]),y=0
                                     ,label = paste0('std:',scales::comma(sd(dt[[col]]),accuracy=0.001)
                                                     ,'\nmean:',scales::comma(mean(dt[[col]]),accuracy=0.001)
                                     ))
             ggplot(data=dt,aes_string(x=col)) +
               ggplot2::geom_density() +
               geom_text(data=annotation,aes(x=x,y=y,label=label),color='blue',hjust=0,size=3,vjust=-1)
           }
           
)
cowplot::plot_grid(plotlist = p,nrow = ceiling(length(numCols)/5),ncol =5 , label_size=5)

```
### Correlation
```{r fig.height=10, fig.width=10}
dataCor = cor(dataRaw[-NAsRows,numCols])
dataCorDF = as.data.frame(as.table(dataCor))

highCorr = filter(dataCorDF,abs(Freq)>0.9, Var1 != Var2) %>% arrange(-Freq)
print(highCorr)


corrplot::corrplot(dataCor
                   ,method='square'
                   ,type='full'
                   ,order='AOE')


```


### Correlation with Target

```{r fig.height=20, fig.width=10}
summ_fun <- function(x){
  return(rbind(data.frame(y=min(x),label = paste0('avg: ',scales::comma(mean(x),accuracy=0.01)))))
}

p = lapply(numCols 
           ,function(col){
             dt=dataRaw[-NAsRows,]
             dt$target = as.factor(dt$y)
             ggplot(data=dt,aes_string(y=col,group='target',x='target',fill='target')) +
               ggplot2::geom_violin(color="#88888820")+
               ggplot2::geom_boxplot(outlier.color = NA,width=0.2)  +
               ggplot2::stat_summary( fun.data=summ_fun,geom='text',color='blue',size=3#,hjust=0
                                      #,position=ggplot2::position_nudge(x=0.2)
               ) +
               
               scale_fill_brewer(palette ='Blues') +
               scale_color_brewer(palette ='Blues')  +
               ggplot2::theme(text = element_text(size=10)
                              ,axis.text.x = element_text(angle=90,size=10)
                              ,legend.position = "none"
               )
           }
           
)
cowplot::plot_grid(plotlist = p,nrow = ceiling(length(numCols)/5),ncol =5 , label_size=2)

```

## Qualitative Columns

```{r fig.height=20, fig.width=10}

textCols = colnames(dataRaw)[which(lapply(dataRaw,class)!='numeric')]
```

### Checking Missing Values

```{r}
NAs = sapply(textCols,function(col){sum(is.na(dataRaw[[col]]))})
print(NAs)
NAsRowsText = unique(unlist(lapply(textCols,function(col){which(is.na(dataRaw[[col]]))})))
print(length(NAsRowsText))
NAsRows = c(NAsRows,NAsRowsText)
```
### Count of Records
```{r}
uniqueCounts = sapply(textCols,function(x)length(unique(dataRaw[[x]])))
uniqueCounts
#remove x37 as too many details

```


### Variables Distribution

```{r fig.height=10, fig.width=10}


p = lapply(textCols
           ,function(col){
             dt=dataRaw
             dt[[col]]=forcats::fct_reorder(factor(dataRaw[[col]]),.x = factor(dataRaw[[col]]), .fun = length)
             ggplot(data=dt,aes_string(x=col
                                       ,fill=col)) +
               ggplot2::geom_bar() +
               geom_text(stat='count', aes(
                 #label=comma(..count..,accuracy=1)
                 label=paste0(comma(..count..,accuracy=1),'\n(',percent(..count../sum(..count..),accuracy=1),')')
               ), size=3,vjust=1 ) +
               #scale_fill_brewer(palette ='Blues') +
               ggplot2::theme(text = element_text(size=10)
                              ,axis.text.x = element_text(angle=90,size=10)
                              ,legend.position = "none")
           }
           
)
cowplot::plot_grid(plotlist = p,nrow = ceiling(length(textCols)/2),ncol =2 , label_size=5)

```



### Correlation with Target

```{r fig.height=10, fig.width=10}

p = lapply(textCols[textCols!='y']
           ,function(col){
             dt=dataRaw %>%
               mutate(col=.[[col]]) %>%
               group_by(col,y) %>%
               summarize(count = n()) %>%
               group_by(col) %>%
               mutate(label=paste0(comma(count,accuracy=1),' (', percent(count/sum(count)),')')
                      ,tot= sum(count)) %>%
               ungroup() %>%
               mutate(col=forcats::fct_reorder(factor(col),tot))
             
             Ncol = '#2b8cbe'
             Ycol = '#a6bddb'
             ynote = levels(dt$col)[ceiling(length(levels(dt$col))/2)]
             note=rbind(data.frame(y=ynote,x=max(filter(dt,y=='y')$count)
                                   ,label='Y = 1',color=Ycol,alpha=1,hjust=0,angle=90)
                        ,data.frame(y=ynote,x=-max(filter(dt,y=='n')$count)
                                    ,label='Y = 0',color=Ncol,alpha=1,hjust=0,angle=90)
             )
             
             dtY = filter(dt,y=='y')
             dtN = filter(dt,y=='n')
             
             p=ggplot(data=dt,aes(y=col,fill=col)) +
               ggplot2::geom_col(data=dtY,aes(x=count),fill='#2b8cbe')+
               ggplot2::geom_text(data=dtY,aes(x=1,label=label),size=3,hjust=-.5)+
               ggplot2::geom_col(data=dtN,aes(x=-count),fill='#a6bddb') +
               ggplot2::geom_text(data=dtN,aes(x=-1,label=label),size=3,hjust=1.5,alpha=0.7)+
               ggplot2::geom_text(data=note,aes(x=x,y=y,label=label,alpha=alpha,hjust=hjust,angle=angle)
                                  ,inherit.aes = F,size=5) +
               ggplot2::ggtitle(paste0('Y=0 vs. Y=1 for column ', col)) +
               ggplot2::theme(text = element_text(size=10)
                              ,axis.text.x = element_text(angle=90,size=10)
                              ,legend.position = "none")
             #ggplot2::scale_fill_brewer('blues')
             
           }
           
)
cowplot::plot_grid(plotlist = p,nrow = 2,ncol =2 , label_size=2)

```


# Data Cleaning

```{r}
# Removing Nas
data = dataRaw[-NAsRows,] %>%
  select(-c(x6,x41))
```

# Model XGBoost

## Data Setup

```{r}

seed=1701
message(rep('=',30))
message('Processing Model: XGB, Name:')
message(rep('=',30))
message('Train and Test')
trainIndex <- createDataPartition(data$y, p = .8, list = FALSE, times = 1)
dataTrain = data[trainIndex,]
dataTest =  data[-trainIndex,]
target = 'y'
predictors = names(data)[names(data)!= target]
message("Ratio y: ", round(sum(dataTrain$y=='y')/nrow(dataTrain),3))
message("Records: ", nrow(dataTrain))
message("Predictors: ", length(predictors))
```
## Model Setting
```{r}
stats <- function (data, lev =  levels(data$obs), model = NULL)  {
  cmY = caret::confusionMatrix(data$pred,data$obs,positive='y',mode='everything')
  cmN = caret::confusionMatrix(data$pred,data$obs,positive='n',mode='everything')
  tc = caret::twoClassSummary(data, lev = c('n','y'),model)
  recallW = as.numeric(((cmN$byClass['Recall'] * sum(data$obs=='n'))
                        +(cmY$byClass['Recall'] * sum(data$obs=='y')))/length(data$obs))
  #AUC = as.numeric(caret::prSummary(data, lev = c('y','n'))['AUC'])
  roc <- pROC::roc(response = data$obs=='y', predictor = data$y,percent=T)
  prevalence = sum(data$pred =='y')/(nrow(data))
  limit=pROC::coords(roc, x="best",input='thr', ret='all',best.method = 'y',best.weights = c(5,prevalence),transpose=FALSE)
  bestThreshold = limit$threshold
  
  AUC = as.numeric(pROC::auc(roc))/100
  AUC_recallW = (AUC) * (recallW)
  c(#postResample(data[, "pred"], data[, "obs"])
    cmY$overall
    ,cmY$byClass #Sens =caret::sensitivity(data[, "pred"], data[, "obs"], lev[1])
    ,tc
    ,AUC=AUC
    ,recallW =  recallW
    ,precisionW =  as.numeric(((cmN$byClass['Precision'] * sum(data$obs=='n'))
                               +(cmY$byClass['Precision'] * sum(data$obs=='y')))/length(data$obs))
    ,AUC_recallW = AUC_recallW
    ,bestThreshold=bestThreshold
  )
}

trControl <- trainControl(method = "boot" #boot - adaptive_boot" #https://lagunita.stanford.edu/c4x/HumanitiesScience/StatLearning/asset/cv_boot.pdf
                          #https://topepo.github.io/caret/adaptive-resampling.html
                          ,number =10
                          ,classProbs=TRUE
                          ,summaryFunction=stats
                          ,allowParallel = T
                          ,search='random' #random, grid
                          ,trim=T
)

tuneGrid = expand.grid(nrounds= seq(from=500,to=1000, length.out =4) #800
                       ,max_depth=c(20,30,40)
                       ,eta = c(0.1)
                       ,gamma= c(0)   #5 #https://medium.com/data-design/xgboost-hi-im-gamma-what-can-i-do-for-you-and-the-tuning-of-regularization-a42ea17e6ab6
                       ,colsample_bytree=c(0.6,0.7) #0.6
                       ,min_child_weight=c(1) 
                       ,subsample   = 1 # c(1,1.5) # 0.6
                       
)
```

## Model Run
```{r}
message(rep('=',30))
message('Model Fit')

set.seed(1701)
maxCores=16
doFuture::registerDoFuture()
future::plan(multiprocess,workers=min(availableCores(),maxCores))

message('modeling')
message('dataset size: ', round(pryr::object_size(dataTrain)/1024^2,2),"MB")
formula = as.formula(paste(target,'~',paste0(predictors,collapse='+')))
print(Sys.time());tic()
model=NULL
model <- caret::train(formula
                      ,data = data.frame(dataTrain)
                      ,method = "xgbTree"
                      ,verbose=TRUE
                      ,tuneGrid = tuneGrid
                      #,tuneGrid = tunedParams
                      # ,objective = "binary:logistic"
                      ,trControl = trControl
                      ,metric ="F1" #F1, #AUC_recallW, Recall
                      ,maximize=T
                      #,verbose=T
                      #,na.action = na.omit
                      
)
toc()
model$modelMetrics = model$results[as.numeric(row.names(model$bestTune)),]
print(model$modelMetrics[c('F1','Precision','Recall','recallW','AUC','AUC_recallW')])
model$bestTune
#stopCluster(cl)
future::plan(sequential)
message(rep('=',30))
message('Saving Model')
modelName = paste0(folder,'model_1122.RDS')
saveRDS(model,file=modelName)
```


# Validation

```{r}
model = readRDS(file=modelName)
message(rep('=',30))
message('Validation: Prediction')
dataPred = dataTest %>% select(-y)
prob =  predict(model,dataPred,type = "prob",na.remove=F)[,'y']
#pred =  predict(model,dataPred,na.remove=F)
#pred =  factor(ifelse(prob>= model$modelMetrics$bestThreshold,'y','n'),levels=c('n','y'))
dataPred = dataPred %>%
  mutate(y_prob = prob
         ,pred =  factor(ifelse(y_prob>= model$modelMetrics$bestThreshold,'y','n'),levels=c('n','y'))
         ,obs=factor(dataTest$y,levels=c('n','y'))
  )



```

## MEtrics

```{r}
message('Validation: Metrics')
validationMetrics=stats(dataPred)
print(validationMetrics[c('F1','Precision','Recall','recallW','AUC','AUC_recallW')])

confMatrix = dataPred %>%
  group_by(obs,pred) %>%
  summarize(count=n()) %>%
  group_by(obs) %>%
  summarize(perc = count/sum(count)
            ,label=paste0(scales::percent(perc),' ',comma(count))
            ,obs = obs
            ,evaluation = ifelse(obs==pred,'Correct','Wrong'))


```

## Plot Conf Matrix

```{r}
p=ggplot(data=confMatrix,aes_string(x='obs',y='perc',label='label',fill='evaluation'))+
  geom_bar(position = 'stack',stat='identity') +
  geom_text(aes(vjust=ifelse(perc>0.1,1.1,-.1),color=evaluation),position='stack',size=5,check_overlap = T) +
  xlab('Actual value of Y') +
  scale_fill_manual(values=c('Correct' = '#1b9e77','Wrong'='#d95f02'))+
  scale_color_manual(values=c('Correct' = 'darkgreen','Wrong'='darkred'))
p
```

## ROC
```{r}

roc <- pROC::roc(response = dataPred$obs, predictor =dataPred$y_prob,percent=T)
plot(roc)

```

## Feature Importnace
```{r}

vi=varImp(model)
plot(vi,20)
vit=data.frame(importance = vi$importance$Overall)
vit$predictor = rownames(vi$importance)

```

