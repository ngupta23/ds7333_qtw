{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://scikit-learn.org/stable/auto_examples/impute/plot_missing_values.html#sphx-glr-auto-examples-impute-plot-missing-values-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Imputing missing values before building an estimator\n",
    "\n",
    "\n",
    "Missing values can be replaced by the mean, the median or the most frequent\n",
    "value using the basic :class:`sklearn.impute.SimpleImputer`.\n",
    "\n",
    "In this example we will investigate different imputation techniques:\n",
    "\n",
    "- imputation by the constant value 0\n",
    "- imputation by the mean value of each feature combined with a missing-ness\n",
    "  indicator auxiliary variable\n",
    "- k nearest neighbor imputation\n",
    "- iterative imputation\n",
    "\n",
    "We will use two datasets: Diabetes dataset which consists of 10 feature\n",
    "variables collected from diabetes patients with an aim to predict disease\n",
    "progression and California Housing dataset for which the target is the median\n",
    "house value for California districts.\n",
    "\n",
    "As neither of these datasets have missing values, we will remove some\n",
    "values to create new versions with artificially missing data. The performance\n",
    "of\n",
    ":class:`~sklearn.ensemble.RandomForestRegressor` on the full original dataset\n",
    "is then compared the performance on the altered datasets with the artificially\n",
    "missing values imputed using different techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Authors: Maria Telenczuk  <https://github.com/maikia>\n",
    "# License: BSD 3 clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data and make missing values sets\n",
    "###############################################\n",
    "\n",
    " First we download the two datasets. Diabetes dataset is shipped with\n",
    " scikit-learn. It has 442 entries, each with 10 features. California Housing\n",
    " dataset is much larger with 20640 entries and 8 features. It needs to be\n",
    " downloaded. We will only use the first 400 entries for the sake of speeding\n",
    " up the calculations but feel free to use the whole dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "X_california, y_california = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "def add_missing_values(X_full, y_full):\n",
    "    n_samples, n_features = X_full.shape\n",
    "\n",
    "    # Add missing values in 75% of the lines\n",
    "    missing_rate = 0.75\n",
    "    n_missing_samples = int(n_samples * missing_rate)\n",
    "\n",
    "    missing_samples = np.zeros(n_samples, dtype=np.bool)\n",
    "    missing_samples[: n_missing_samples] = True\n",
    "\n",
    "    rng.shuffle(missing_samples)\n",
    "    missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "    X_missing = X_full.copy()\n",
    "    X_missing[missing_samples, missing_features] = np.nan\n",
    "    y_missing = y_full.copy()\n",
    "\n",
    "    return X_missing, y_missing\n",
    "\n",
    "\n",
    "X_miss_california, y_miss_california = add_missing_values(X_california, y_california)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute the missing data and score\n",
    "#################################\n",
    "Now we will write a function which will score the results on the differently\n",
    "imputed data. Let's look at each imputer separately:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# To use the experimental IterativeImputer, we need to explicitly ask for it:\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "N_SPLITS = 5\n",
    "regressor = RandomForestRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing information\n",
    "-------------------\n",
    "In addition to imputing the missing values, the imputers have an\n",
    "`add_indicator` parameter that marks the values that were missing, which\n",
    "might carry some information.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_for_imputer(imputer, X_missing, y_missing):\n",
    "    estimator = make_pipeline(imputer, regressor)\n",
    "    impute_scores = cross_val_score(estimator, X_missing, y_missing,\n",
    "                                    scoring='neg_mean_squared_error',\n",
    "                                    cv=N_SPLITS)\n",
    "    return impute_scores\n",
    "\n",
    "\n",
    "x_labels = ['Full data',\n",
    "            'Zero imputation',\n",
    "            'Mean Imputation',\n",
    "            'KNN Imputation',\n",
    "            'Iterative Imputation']\n",
    "\n",
    "mses_california = np.zeros(5)\n",
    "stds_california = np.zeros(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the score\n",
    "------------------\n",
    "First, we want to estimate the score on the original data:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_score(X_full, y_full):\n",
    "    full_scores = cross_val_score(regressor, X_full, y_full,\n",
    "                                  scoring='neg_mean_squared_error',\n",
    "                                  cv=N_SPLITS)\n",
    "    return full_scores.mean(), full_scores.std()\n",
    "\n",
    "\n",
    "mses_california[0], stds_california[0] = get_full_score(X_california, y_california)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace missing values by 0\n",
    "---------------------------\n",
    "\n",
    "Now we will estimate the score on the data where the missing values are\n",
    "replaced by 0:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_zero_score(X_missing, y_missing):\n",
    "\n",
    "    imputer = SimpleImputer(missing_values=np.nan, add_indicator=True,\n",
    "                            strategy='constant', fill_value=0)\n",
    "    zero_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing)\n",
    "    return zero_impute_scores.mean(), zero_impute_scores.std()\n",
    "\n",
    "\n",
    "mses_california[1], stds_california[1] = get_impute_zero_score(\n",
    "    X_miss_california, y_miss_california)\n",
    "mses_diabetes[1], stds_diabetes[1] = get_impute_zero_score(X_miss_diabetes,\n",
    "                                                           y_miss_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN-imputation of the missing values\n",
    "------------------------------------\n",
    "\n",
    ":class:`sklearn.impute.KNNImputer` imputes missing values using the weighted\n",
    "or unweighted mean of the desired number of nearest neighbors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_knn_score(X_missing, y_missing):\n",
    "    imputer = KNNImputer(missing_values=np.nan, add_indicator=True)\n",
    "    knn_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing)\n",
    "    return knn_impute_scores.mean(), knn_impute_scores.std()\n",
    "\n",
    "\n",
    "mses_california[2], stds_california[2] = get_impute_knn_score(\n",
    "    X_miss_california, y_miss_california)\n",
    "mses_diabetes[2], stds_diabetes[2] = get_impute_knn_score(X_miss_diabetes,\n",
    "                                                          y_miss_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing values with mean\n",
    "-------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_mean(X_missing, y_missing):\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\",\n",
    "                            add_indicator=True)\n",
    "    mean_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing)\n",
    "    return mean_impute_scores.mean(), mean_impute_scores.std()\n",
    "\n",
    "\n",
    "mses_california[3], stds_california[3] = get_impute_mean(X_miss_california,\n",
    "                                                         y_miss_california)\n",
    "mses_diabetes[3], stds_diabetes[3] = get_impute_mean(X_miss_diabetes,\n",
    "                                                     y_miss_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative imputation of the missing values\n",
    "------------------------------------------\n",
    "\n",
    "Another option is the :class:`sklearn.impute.IterativeImputer`. This uses\n",
    "round-robin linear regression, modeling each feature with missing values as a\n",
    "function of other features, in turn.\n",
    "The version implemented assumes Gaussian (output) variables. If your features\n",
    "are obviously non-normal, consider transforming them to look more normal\n",
    "to potentially improve performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_iterative(X_missing, y_missing):\n",
    "    imputer = IterativeImputer(missing_values=np.nan, add_indicator=True,\n",
    "                               random_state=0, n_nearest_features=5,\n",
    "                               sample_posterior=True)\n",
    "    iterative_impute_scores = get_scores_for_imputer(imputer,\n",
    "                                                     X_missing,\n",
    "                                                     y_missing)\n",
    "    return iterative_impute_scores.mean(), iterative_impute_scores.std()\n",
    "\n",
    "\n",
    "mses_california[4], stds_california[4] = get_impute_iterative(\n",
    "    X_miss_california, y_miss_california)\n",
    "mses_diabetes[4], stds_diabetes[4] = get_impute_iterative(X_miss_diabetes,\n",
    "                                                          y_miss_diabetes)\n",
    "\n",
    "mses_diabetes = mses_diabetes * -1\n",
    "mses_california = mses_california * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results\n",
    "################\n",
    "\n",
    "Finally we are going to visualize the score:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "n_bars = len(mses_diabetes)\n",
    "xval = np.arange(n_bars)\n",
    "\n",
    "colors = ['r', 'g', 'b', 'orange', 'black']\n",
    "\n",
    "# plot diabetes results\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax1 = plt.subplot(121)\n",
    "for j in xval:\n",
    "    ax1.barh(j, mses_diabetes[j], xerr=stds_diabetes[j],\n",
    "             color=colors[j], alpha=0.6, align='center')\n",
    "\n",
    "ax1.set_title('Imputation Techniques with Diabetes Data')\n",
    "ax1.set_xlim(left=np.min(mses_diabetes) * 0.9,\n",
    "             right=np.max(mses_diabetes) * 1.1)\n",
    "ax1.set_yticks(xval)\n",
    "ax1.set_xlabel('MSE')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_yticklabels(x_labels)\n",
    "\n",
    "# plot california dataset results\n",
    "ax2 = plt.subplot(122)\n",
    "for j in xval:\n",
    "    ax2.barh(j, mses_california[j], xerr=stds_california[j],\n",
    "             color=colors[j], alpha=0.6, align='center')\n",
    "\n",
    "ax2.set_title('Imputation Techniques with California Data')\n",
    "ax2.set_yticks(xval)\n",
    "ax2.set_xlabel('MSE')\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_yticklabels([''] * n_bars)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# You can also try different techniques. For instance, the median is a more\n",
    "# robust estimator for data with high magnitude variables which could dominate\n",
    "# results (otherwise known as a 'long tail')."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
